{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'date', 'tags', 'title', 'url'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "with open('train_new.json') as f:\n",
    "    data1=json.load(f)\n",
    "\n",
    "data1.keys()\n",
    "#pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'date', 'tags', 'title', 'url'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test_new.json') as f:\n",
    "    data2=json.load(f)\n",
    "\n",
    "data1.keys()\n",
    "#pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  Approximately 1.6 million model-year 2015-18 F...\n",
      "1  Approximately 192,000 model-year 2016-18 Toyot...\n",
      "2  Nobody likes when things don't work the way th...\n",
      "3  Approximately 19,400 model-year 2012 Toyota Av...\n",
      "4  Approximately 8,400 model-year 2017-18 Volkswa...\n",
      "(2815, 1)\n"
     ]
    }
   ],
   "source": [
    "#Prepare text data\n",
    "\n",
    "import pandas as pd\n",
    "set=[]\n",
    "for k,v in data1['content'].items():\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    set.append(v)\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "for k,v in data2['content'].items():\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    set.append(v)\n",
    "    \n",
    "df1=pd.DataFrame(set)\n",
    "print(df1.head())\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.columns=['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Approximately 1.6 million model-year 2015-18 F...\n",
       "1       Approximately 192,000 model-year 2016-18 Toyot...\n",
       "2       Nobody likes when things don't work the way th...\n",
       "3       Approximately 19,400 model-year 2012 Toyota Av...\n",
       "4       Approximately 8,400 model-year 2017-18 Volkswa...\n",
       "5       Approximately 9,000 model-year 2018 Mercedes-B...\n",
       "6       Approximately 12,800 model-year 2018 Jeep Rene...\n",
       "7       Approximately 154,000 model-year 2018-19 Dodge...\n",
       "8       Approximately 90 model-year 2018 Ford Edge and...\n",
       "9       Approximately 49,000 model-year 2012-15 Ford F...\n",
       "10      Approximately 470 model-year 2018 Mercedes-Ben...\n",
       "11      Approximately 3,300 model-year 2018 Genesis G8...\n",
       "12      Approximately 300 model-year 2019 Subaru Ascen...\n",
       "13      Approximately 65 model-year 2018 Chrysler Paci...\n",
       "14      12 model-year 2018 BMW 540d xDrive sedans\\n Th...\n",
       "15      's 2018 Volkswagen Atlas, a long-term test veh...\n",
       "16      Nobody likes when things don't work the way th...\n",
       "17      As the owner of a Mercedes-AMG G65, you make y...\n",
       "18      Given the sheer thrill of driving an 840-horse...\n",
       "19      Approximately 10,800 model-year 2017-18 Merced...\n",
       "20      Approximately 5,600 model-year 2018-19 BMW X3 ...\n",
       "21      Approximately 33,100 model-year 2015-18 Volksw...\n",
       "22      If you're driving a model-year 2015 or 2016 La...\n",
       "23      Approximately 6,600 model-year 2013-15 Audi S8...\n",
       "24      Approximately 680 model-year 2018 Mazda CX-5 S...\n",
       "25      Getting a recall notice for your vehicle isn't...\n",
       "26      In the time it will take me to write this aler...\n",
       "27      Approximately 504,000 model-year 2013-14 Ford ...\n",
       "28      Approximately 700 model-year 2017-18 Porsche P...\n",
       "29      Approximately 1,800 model-year 2018 Dodge Jour...\n",
       "                              ...                        \n",
       "2785    Nissan and Infiniti are the latest automakers ...\n",
       "2786    In advertisements that help sell thousands of ...\n",
       "2787    Faulty Takata airbag inflators keep taking the...\n",
       "2788    General Motors has announced yet another spraw...\n",
       "2789    General Motors issued six more recalls on Wedn...\n",
       "2790    The ignition switch defects that engulfed Gene...\n",
       "2791    The public might associated ignition switch re...\n",
       "2792    At this point, there's little question that Ge...\n",
       "2793    General Motors has issued a stop-sale order on...\n",
       "2794    Kia is recalling certain 2014 models of its ad...\n",
       "2795    You may remember that Jeep's unusual fix for t...\n",
       "2796    Investigations into the General Motors ignitio...\n",
       "2797    We just can't seem to get away from recalls in...\n",
       "2798    DETROIT (AP) - BMW is expanding a recall of it...\n",
       "2799    It's barely arrived in dealerships, and alread...\n",
       "2800    Mercedes-Benz is the latest automaker to be af...\n",
       "2801    Investigators at the National Highway Traffic ...\n",
       "2802    Dodge and Jeep are announcing recalls of a tot...\n",
       "2803    The Acura ILX just can't seem to catch a break...\n",
       "2804    Most of the recalls we cover involve four-whee...\n",
       "2805    \"It will be done through cash on hand, no insu...\n",
       "2806    Volkswagen is issuing a stop-sale and recall f...\n",
       "2807    Ford is announcing six separate recalls for a ...\n",
       "2808    Through the first six months of 2014, General ...\n",
       "2809    Hyundai is recalling 58,000 Elantra Touring wa...\n",
       "2810    The scope of the problem with the faulty airba...\n",
       "2811    Lotus is recalling 860 vehicles after discover...\n",
       "2812    Jeep's saga with the National Traffic Safety A...\n",
       "2813    Subaru is recalling 660,238 vehicles located i...\n",
       "2814    No, that headline isn't a typo â€“ General Motor...\n",
       "Name: a, Length: 2815, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\slegl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\slegl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\slegl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "mystopwords=stopwords.words(\"English\") + ['one', 'become', 'get', 'make', 'take', 'recall','said', 'say', 'could', 'nhtsa', 'n\\'t', 'may', 'vehicle', 'car']\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "def pre_process(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens=[ WNlemma.lemmatize(t.lower()) for t in tokens]\n",
    "    tokens=[ t for t in tokens if t not in mystopwords]\n",
    "    tokens = [ t for t in tokens if len(t) >= 3 ]\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pre-process data\n",
    "\n",
    "toks_train = df1['a'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slegl\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import gensim \n",
    "from gensim import corpora\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-16 11:55:36,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-10-16 11:55:36,842 : INFO : built Dictionary(25451 unique tokens: ['1.6', '2015-18', 'approximately', 'area', 'b-pillar']...) from 2815 documents (total 516136 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(25451 unique tokens: ['1.6', '2015-18', 'approximately', 'area', 'b-pillar']...)\n"
     ]
    }
   ],
   "source": [
    "# Prepare a vocabulary dictionary.\n",
    "dictionary = corpora.Dictionary(toks_train)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train = [dictionary.doc2bow(d) for d in toks_train ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-16 11:55:51,589 : INFO : using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "2018-10-16 11:55:51,593 : INFO : using symmetric eta at 0.2\n",
      "2018-10-16 11:55:51,605 : INFO : using serial LDA version on this node\n",
      "2018-10-16 11:55:51,638 : INFO : running online (single-pass) LDA training, 5 topics, 1 passes over the supplied corpus of 2815 documents, updating model once every 2000 documents, evaluating perplexity every 2815 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-10-16 11:55:51,638 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2018-10-16 11:55:51,638 : INFO : PROGRESS: pass 0, at document #2000/2815\n",
      "2018-10-16 11:55:55,106 : INFO : optimized alpha [0.33097643, 0.30232117, 0.28734493, 0.29300487, 0.29629004]\n",
      "2018-10-16 11:55:55,106 : INFO : merging changes from 2000 documents into a model of 2815 documents\n",
      "2018-10-16 11:55:55,131 : INFO : topic #0 (0.331): 0.010*\"owner\" + 0.010*\"safety\" + 0.009*\"model\" + 0.006*\"toyota\" + 0.006*\"year\" + 0.006*\"dealer\" + 0.006*\"issue\" + 0.005*\"affected\" + 0.005*\"ford\" + 0.005*\"highway\"\n",
      "2018-10-16 11:55:55,131 : INFO : topic #1 (0.302): 0.013*\"model\" + 0.009*\"owner\" + 0.008*\"toyota\" + 0.008*\"safety\" + 0.006*\"year\" + 0.006*\"problem\" + 0.005*\"also\" + 0.005*\"ford\" + 0.005*\"dealer\" + 0.005*\"affected\"\n",
      "2018-10-16 11:55:55,135 : INFO : topic #2 (0.287): 0.013*\"safety\" + 0.010*\"problem\" + 0.007*\"owner\" + 0.006*\"affected\" + 0.006*\"dealer\" + 0.006*\"honda\" + 0.005*\"model\" + 0.005*\"also\" + 0.004*\"customer\" + 0.004*\"year\"\n",
      "2018-10-16 11:55:55,135 : INFO : topic #3 (0.293): 0.009*\"safety\" + 0.009*\"toyota\" + 0.008*\"model\" + 0.007*\"year\" + 0.007*\"number\" + 0.006*\"problem\" + 0.006*\"owner\" + 0.006*\"chrysler\" + 0.005*\"national\" + 0.005*\"company\"\n",
      "2018-10-16 11:55:55,139 : INFO : topic #4 (0.296): 0.012*\"toyota\" + 0.009*\"owner\" + 0.008*\"problem\" + 0.008*\"safety\" + 0.008*\"model\" + 0.006*\"affected\" + 0.006*\"dealer\" + 0.005*\"year\" + 0.005*\"also\" + 0.004*\"company\"\n",
      "2018-10-16 11:55:55,143 : INFO : topic diff=3.071746, rho=1.000000\n",
      "2018-10-16 11:55:59,185 : INFO : -8.284 per-word bound, 311.6 perplexity estimate based on a held-out corpus of 815 documents with 180192 words\n",
      "2018-10-16 11:55:59,185 : INFO : PROGRESS: pass 0, at document #2815/2815\n",
      "2018-10-16 11:56:00,895 : INFO : optimized alpha [0.37126535, 0.30754846, 0.27073964, 0.25047374, 0.24513611]\n",
      "2018-10-16 11:56:00,895 : INFO : merging changes from 815 documents into a model of 2815 documents\n",
      "2018-10-16 11:56:00,915 : INFO : topic #0 (0.371): 0.011*\"owner\" + 0.010*\"safety\" + 0.009*\"model\" + 0.009*\"affected\" + 0.008*\"ford\" + 0.007*\"issue\" + 0.007*\"dealer\" + 0.006*\"year\" + 0.006*\"number\" + 0.005*\"airbag\"\n",
      "2018-10-16 11:56:00,919 : INFO : topic #1 (0.308): 0.011*\"model\" + 0.009*\"owner\" + 0.009*\"ford\" + 0.009*\"safety\" + 0.008*\"2015\" + 0.007*\"affected\" + 0.006*\"2014\" + 0.006*\"year\" + 0.006*\"dealer\" + 0.006*\"fuel\"\n",
      "2018-10-16 11:56:00,923 : INFO : topic #2 (0.271): 0.011*\"safety\" + 0.010*\"honda\" + 0.009*\"takata\" + 0.007*\"affected\" + 0.007*\"inflator\" + 0.007*\"problem\" + 0.007*\"owner\" + 0.005*\"automaker\" + 0.005*\"customer\" + 0.005*\"company\"\n",
      "2018-10-16 11:56:00,923 : INFO : topic #3 (0.250): 0.009*\"safety\" + 0.008*\"chrysler\" + 0.008*\"number\" + 0.007*\"model\" + 0.007*\"year\" + 0.006*\"owner\" + 0.006*\"company\" + 0.005*\"2014\" + 0.005*\"affected\" + 0.005*\"problem\"\n",
      "2018-10-16 11:56:00,923 : INFO : topic #4 (0.245): 0.009*\"toyota\" + 0.009*\"owner\" + 0.008*\"safety\" + 0.008*\"problem\" + 0.006*\"model\" + 0.006*\"affected\" + 0.006*\"dealer\" + 0.005*\"service\" + 0.005*\"also\" + 0.005*\"company\"\n",
      "2018-10-16 11:56:00,923 : INFO : topic diff=1.637869, rho=0.707107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.34 s\n"
     ]
    }
   ],
   "source": [
    "# Build an LDA model for 3 topics out of the DTM\n",
    "%time lda = gensim.models.ldamodel.LdaModel(dtm_train, num_topics = 5,  alpha='auto',id2word = dictionary)\n",
    "#chunksize (int, optional) â€“ Number of documents to be used in each training chunk.\n",
    "#passes (int, optional) â€“ Number of passes through the corpus during training.\n",
    "#chunksize=30,\n",
    "#passes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"owner\" + 0.010*\"safety\" + 0.009*\"model\" + 0.009*\"affected\" + 0.008*\"ford\" + 0.007*\"issue\" + 0.007*\"dealer\" + 0.006*\"year\" + 0.006*\"number\" + 0.005*\"airbag\"'),\n",
       " (1,\n",
       "  '0.011*\"model\" + 0.009*\"owner\" + 0.009*\"ford\" + 0.009*\"safety\" + 0.008*\"2015\" + 0.007*\"affected\" + 0.006*\"2014\" + 0.006*\"year\" + 0.006*\"dealer\" + 0.006*\"fuel\"'),\n",
       " (2,\n",
       "  '0.011*\"safety\" + 0.010*\"honda\" + 0.009*\"takata\" + 0.007*\"affected\" + 0.007*\"inflator\" + 0.007*\"problem\" + 0.007*\"owner\" + 0.005*\"automaker\" + 0.005*\"customer\" + 0.005*\"company\"'),\n",
       " (3,\n",
       "  '0.009*\"safety\" + 0.008*\"chrysler\" + 0.008*\"number\" + 0.007*\"model\" + 0.007*\"year\" + 0.006*\"owner\" + 0.006*\"company\" + 0.005*\"2014\" + 0.005*\"affected\" + 0.005*\"problem\"'),\n",
       " (4,\n",
       "  '0.009*\"toyota\" + 0.009*\"owner\" + 0.008*\"safety\" + 0.008*\"problem\" + 0.006*\"model\" + 0.006*\"affected\" + 0.006*\"dealer\" + 0.005*\"service\" + 0.005*\"also\" + 0.005*\"company\"')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most probable words in each topic. \n",
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"owner\" + 0.010*\"safety\" + 0.009*\"model\" + 0.009*\"affected\" + 0.008*\"ford\" + 0.007*\"issue\" + 0.007*\"dealer\" + 0.006*\"year\" + 0.006*\"number\" + 0.005*\"airbag\"'),\n",
       " (1,\n",
       "  '0.011*\"model\" + 0.009*\"owner\" + 0.009*\"ford\" + 0.009*\"safety\" + 0.008*\"2015\" + 0.007*\"affected\" + 0.006*\"2014\" + 0.006*\"year\" + 0.006*\"dealer\" + 0.006*\"fuel\"'),\n",
       " (2,\n",
       "  '0.011*\"safety\" + 0.010*\"honda\" + 0.009*\"takata\" + 0.007*\"affected\" + 0.007*\"inflator\" + 0.007*\"problem\" + 0.007*\"owner\" + 0.005*\"automaker\" + 0.005*\"customer\" + 0.005*\"company\"'),\n",
       " (3,\n",
       "  '0.009*\"safety\" + 0.008*\"chrysler\" + 0.008*\"number\" + 0.007*\"model\" + 0.007*\"year\" + 0.006*\"owner\" + 0.006*\"company\" + 0.005*\"2014\" + 0.005*\"affected\" + 0.005*\"problem\"'),\n",
       " (4,\n",
       "  '0.009*\"toyota\" + 0.009*\"owner\" + 0.008*\"safety\" + 0.008*\"problem\" + 0.006*\"model\" + 0.006*\"affected\" + 0.006*\"dealer\" + 0.005*\"service\" + 0.005*\"also\" + 0.005*\"company\"')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics(num_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
